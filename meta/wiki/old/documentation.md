# Alle Notebooks und Ablauf

### Notebooks

| Name                 | Beschreibung                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
|----------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| control-flow         | As described [here](get-started.md), all parameters are set. Main aim however is to call other notebooks in the correct order and mir correct metadata. <br/><br/>Sequences:<br/> 1. Go through source path and save all relevant information from the individual files in the folder for later transformations<br/>2. Parsing of the individual metrics files <br/>3. Parse the individual trace files<br/> 4. Combine traces files in one big file<br/>5. Joining of metricsw data and trace data |
| parsing-metrics      | Here, a single monitoring file is loaded and converted from a nested JSON structure into a data table structure. During this process, timestamps are rounded and unnecessary fields are deleted. Furthermore, the data is heavily filtered based on the parameters. Finally, the file is written to the disk in Parquet format.                                                                                                                                                                                                                               |
| parsing-tracing      | Here, a single trace file is loaded and converted from a nested JSON structure into a data table structure. The data is then written to the disk in Parquet format.                                                                                                                                                                                                                                                                                                                                                                     |
| concat_single_files  | This allows files of the same schema to be combined to create a large file.                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
| join_metrics_tracing | Both tracing data and monitoring data are loaded and joined using a left join on pod name and timestamp. The result is written to the disk as a CSV file.                                                                                                                                                                                                                                                                                                                                                                         |

### Neo4j-Skripte

With the help of the Docker container, the fully transformed data can be loaded into Neo4j. This provides a nice view of your traces through the browser interface. However, there is also a script available that allows you to render the entire graph using Vis.js. This results in a standalone HTML file.


| Name           | Description                                                                                                                                                                                  |
|----------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| dropall-db     | Deletes the whole database of Neo4j.                                                                                                                                                       |
| load-db        | Loads all data into Neo4j. Beforehand, the transformed final data must be copied into Neo4j. In the Docker container, the data must be placed at the following location:<br/>/var/lib/neo4j/import |
| generate-graph | Generates the HTML file with the entire graph that is stored in Neo4j.                                                                                                       |

Attention: These scripts are not parameterized and are very minimal. The input and output paths must be specified individually!
